import os
import uuid
from typing import List, Dict, Any, Optional
from langchain.memory import ConversationBufferMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage

# LLMå®¢æˆ·ç«¯ - å»¶è¿ŸåŠ è½½
_openai_client = None
_llm_available = None

# æ”¯æŒçš„LLMæä¾›å•†é…ç½®
LLM_PROVIDERS = {
    "glm": {
        "env_key": "GLM_API_KEY",
        "base_url": "https://open.bigmodel.cn/api/paas/v4/",
        "default_model": "glm-4-flash"
    },
    "dashscope": {
        "env_key": "DASHSCOPE_API_KEY",
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "default_model": "qwen-plus"
    },
    "openai": {
        "env_key": "OPENAI_API_KEY",
        "base_url": None,
        "default_model": "gpt-3.5-turbo"
    }
}


def _get_openai_client():
    """è·å–OpenAIå…¼å®¹å®¢æˆ·ç«¯ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
    global _openai_client, _llm_available

    if _llm_available is not None:
        return _openai_client if _llm_available else None

    try:
        from openai import OpenAI

        # æŒ‰ä¼˜å…ˆçº§æ£€æµ‹API Keyï¼šGLM > DASHSCOPE > OPENAI
        api_key = None
        base_url = None
        provider_name = None

        # æ£€æµ‹GLMï¼ˆæ™ºè°±AIï¼‰
        if os.getenv("GLM_API_KEY"):
            api_key = os.getenv("GLM_API_KEY")
            base_url = os.getenv("GLM_BASE_URL") or LLM_PROVIDERS["glm"]["base_url"]
            provider_name = "GLM(æ™ºè°±AI)"
        # æ£€æµ‹é€šä¹‰åƒé—®
        elif os.getenv("DASHSCOPE_API_KEY"):
            api_key = os.getenv("DASHSCOPE_API_KEY")
            base_url = os.getenv("DASHSCOPE_BASE_URL") or LLM_PROVIDERS["dashscope"]["base_url"]
            provider_name = "é€šä¹‰åƒé—®"
        # æ£€æµ‹OpenAI
        elif os.getenv("OPENAI_API_KEY"):
            api_key = os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("OPENAI_BASE_URL")
            provider_name = "OpenAI"

        if not api_key:
            print("æœªé…ç½®LLM APIå¯†é’¥ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…æ¨¡å¼")
            print("æ”¯æŒçš„é…ç½®: GLM_API_KEY, DASHSCOPE_API_KEY, OPENAI_API_KEY")
            _llm_available = False
            return None

        client_kwargs = {"api_key": api_key}
        if base_url:
            client_kwargs["base_url"] = base_url

        _openai_client = OpenAI(**client_kwargs)
        _llm_available = True
        print(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ - æä¾›å•†: {provider_name}")
        return _openai_client

    except ImportError:
        print("openaiåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…æ¨¡å¼")
        _llm_available = False
        return None
    except Exception as e:
        print(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…æ¨¡å¼")
        _llm_available = False
        return None


class ChatAgent:
    """AIèŠå¤©æ™ºèƒ½ä½“ - æ”¯æŒçœŸå®LLMçš„å¢å¼ºç‰ˆ"""

    # ç³»ç»Ÿæç¤ºè¯ - å®šä¹‰AIåŠ©æ‰‹çš„ä¸“ä¸šè§’è‰²
    SYSTEM_PROMPT = """ä½ æ˜¯æ™ºæ…§é‡‡è´­ç³»ç»Ÿçš„AIåŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºç ”ç©¶æœºæ„æä¾›é‡‡è´­æœåŠ¡æ”¯æŒã€‚

ä½ çš„èŒè´£ï¼š
1. ååŠ©ç”¨æˆ·è¿›è¡Œé‡‡è´­éœ€æ±‚åˆ†æå’Œå®¡æŸ¥
2. æä¾›ä»·æ ¼æŸ¥è¯¢å’Œæ¯”ä»·å»ºè®®
3. è¯†åˆ«åˆåŒä¸­çš„é£é™©æ¡æ¬¾
4. è§£ç­”é‡‡è´­æµç¨‹ç›¸å…³é—®é¢˜
5. æä¾›ä¾›åº”å•†è¯„ä¼°å»ºè®®

ä½ çš„ç‰¹ç‚¹ï¼š
- ä¸“ä¸šã€å‡†ç¡®ã€é«˜æ•ˆ
- ç†Ÿæ‚‰æ”¿åºœé‡‡è´­æ³•è§„å’Œä¼ä¸šé‡‡è´­æµç¨‹
- èƒ½å¤Ÿè¯†åˆ«éœ€æ±‚æ–‡æ¡£ä¸­çš„æ¨¡ç³Šè¡¨è¿°å’Œé£é™©ç‚¹
- äº†è§£ITè®¾å¤‡ï¼ˆæœåŠ¡å™¨ã€ç½‘ç»œè®¾å¤‡ã€å­˜å‚¨ç­‰ï¼‰çš„é€‰å‹å»ºè®®

å›ç­”è¦æ±‚ï¼š
- å›ç­”ç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡º
- å¯¹äºä¸“ä¸šé—®é¢˜ï¼Œæä¾›å…·ä½“å¯æ“ä½œçš„å»ºè®®
- å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸æ˜ç¡®ï¼Œä¸»åŠ¨è¯¢é—®æ¾„æ¸…
- ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œé€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ äº²å’ŒåŠ›
- å¯¹äºè¶…å‡ºèŒƒå›´çš„é—®é¢˜ï¼Œè¯šå®å‘ŠçŸ¥å¹¶æä¾›æ›¿ä»£å»ºè®®"""

    def __init__(self):
        # å¤šä¼šè¯ç®¡ç†
        self.sessions: Dict[str, Dict[str, Any]] = {}
        self.default_session_id = "default"

        # åˆå§‹åŒ–é»˜è®¤ä¼šè¯
        self._create_session(self.default_session_id)

        # é‡‡è´­ç›¸å…³å…³é”®è¯å’Œå›å¤æ¨¡æ¿ï¼ˆä½œä¸ºé™çº§æ–¹æ¡ˆï¼‰
        self._init_keyword_responses()

        # å°è¯•åˆå§‹åŒ–LLM
        self.llm_client = _get_openai_client()
        self.llm_model = os.getenv("LLM_MODEL") or self._get_default_model()

    def _get_default_model(self) -> str:
        """æ ¹æ®é…ç½®çš„API Keyè‡ªåŠ¨é€‰æ‹©é»˜è®¤æ¨¡å‹"""
        if os.getenv("GLM_API_KEY"):
            return "glm-4-flash"  # GLMé»˜è®¤æ¨¡å‹
        elif os.getenv("DASHSCOPE_API_KEY"):
            return "qwen-plus"  # é€šä¹‰åƒé—®é»˜è®¤æ¨¡å‹
        else:
            return "gpt-3.5-turbo"  # OpenAIé»˜è®¤æ¨¡å‹

    def _init_keyword_responses(self):
        """åˆå§‹åŒ–å…³é”®è¯å“åº”æ˜ å°„ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        self.keyword_responses = {
            "greetings": {
                "keywords": ["ä½ å¥½", "æ‚¨å¥½", "hi", "hello", "æ—©ä¸Šå¥½", "ä¸‹åˆå¥½", "æ™šä¸Šå¥½"],
                "response": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºæ…§é‡‡è´­ç³»ç»Ÿçš„AIåŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨å¤„ç†é‡‡è´­ç›¸å…³çš„é—®é¢˜ã€‚\n\næˆ‘å¯ä»¥ååŠ©æ‚¨è¿›è¡Œï¼š\nâ€¢ éœ€æ±‚å®¡æŸ¥ä¸åˆ†æ\nâ€¢ ä»·æ ¼æŸ¥è¯¢ä¸æ¯”è¾ƒ\nâ€¢ åˆåŒé£é™©è¯†åˆ«\nâ€¢ é‡‡è´­æ–¹æ¡ˆå»ºè®®\n\nè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"
            },
            "price": {
                "keywords": ["ä»·æ ¼", "æŠ¥ä»·", "å¤šå°‘é’±", "è´¹ç”¨", "æˆæœ¬", "é¢„ç®—", "æ¯”ä»·", "è¯¢ä»·", "å®šä»·"],
                "response": "å…³äºä»·æ ¼æŸ¥è¯¢ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n1. **å†å²ä»·æ ¼å‚è€ƒ** - æŸ¥è¯¢åŒç±»äº§å“çš„å†å²é‡‡è´­ä»·æ ¼\n2. **ä»·æ ¼è¶‹åŠ¿åˆ†æ** - äº†è§£ä»·æ ¼æ³¢åŠ¨å’Œèµ°åŠ¿\n3. **å¤šä¾›åº”å•†æ¯”ä»·** - å¯¹æ¯”ä¸åŒä¾›åº”å•†çš„æŠ¥ä»·\n\næ‚¨æƒ³æŸ¥è¯¢å“ªç±»äº§å“çš„ä»·æ ¼ä¿¡æ¯ï¼Ÿ"
            },
            "requirements": {
                "keywords": ["éœ€æ±‚", "é‡‡è´­éœ€æ±‚", "éœ€æ±‚æ–‡æ¡£", "éœ€æ±‚åˆ†æ", "è§„æ ¼", "å‚æ•°", "æŠ€æœ¯è¦æ±‚"],
                "response": "å…³äºéœ€æ±‚å®¡æŸ¥ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n1. **éœ€æ±‚å®Œæ•´æ€§æ£€æŸ¥** - ç¡®è®¤æ˜¯å¦åŒ…å«å¿…è¦çš„å…­è¦ç´ \n2. **æ¨¡ç³Šè¡¨è¿°è¯†åˆ«** - æ£€æµ‹\"ç­‰\"ã€\"çº¦\"ç­‰ä¸æ˜ç¡®è¡¨è¾¾\n3. **æŠ€æœ¯å‚æ•°å®¡æ ¸** - éªŒè¯è§„æ ¼å‚æ•°æ˜¯å¦åˆç†\n\nè¯·ä¸Šä¼ æ‚¨çš„éœ€æ±‚æ–‡æ¡£ï¼Œæˆ–ç›´æ¥æè¿°æ‚¨çš„é‡‡è´­éœ€æ±‚ã€‚"
            },
            "contract": {
                "keywords": ["åˆåŒ", "åè®®", "æ¡æ¬¾", "ç­¾çº¦", "ç­¾ç½²", "åˆåŒåˆ†æ", "é£é™©æ¡æ¬¾"],
                "response": "å…³äºåˆåŒåˆ†æï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n1. **é£é™©æ¡æ¬¾è¯†åˆ«** - æ£€æµ‹å…è´£æ¡æ¬¾ã€æ— é™æœŸæ¡æ¬¾ç­‰é£é™©ç‚¹\n2. **æ¨¡ç³Šè¡¨è¿°æ£€æµ‹** - å‘ç°å¯èƒ½å¯¼è‡´æ­§ä¹‰çš„è¡¨è¿°\n3. **ä¿®æ”¹å»ºè®®** - æä¾›æ¡æ¬¾ä¼˜åŒ–å»ºè®®\n\nè¯·ä¸Šä¼ æ‚¨çš„åˆåŒæ–‡æ¡£ï¼Œæˆ‘å°†ä¸ºæ‚¨è¿›è¡Œå…¨é¢åˆ†æã€‚"
            },
            "server": {
                "keywords": ["æœåŠ¡å™¨", "æœºæ¶å¼", "å¡”å¼", "dell", "hp", "åä¸º", "è”æƒ³", "cpu", "å†…å­˜", "å­˜å‚¨"],
                "response": "å…³äºæœåŠ¡å™¨é‡‡è´­ï¼š\n\n**é€‰å‹å»ºè®®ï¼š**\n- æœºæ¶å¼æœåŠ¡å™¨ï¼šé€‚åˆæœºæˆ¿ç¯å¢ƒï¼Œå¯†åº¦é«˜ï¼Œæ˜“ç®¡ç†\n- å¡”å¼æœåŠ¡å™¨ï¼šé€‚åˆåŠå…¬å®¤ï¼Œå™ªéŸ³ä½ï¼Œæ‰©å±•æ€§å¥½\n\n**å…³é”®é…ç½®ï¼š**\n- CPUï¼šIntel Xeon Silver/Gold/Platinum ç³»åˆ—\n- å†…å­˜ï¼š64GB-512GBï¼ˆæ ¹æ®è´Ÿè½½é€‰æ‹©ï¼‰\n- å­˜å‚¨ï¼šSSDç³»ç»Ÿç›˜ + HDDæ•°æ®ç›˜ + NVMeé«˜é€Ÿå­˜å‚¨\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“ç”¨é€”å’Œé¢„ç®—èŒƒå›´ã€‚"
            },
            "analysis": {
                "keywords": ["åˆ†æ", "è¯„ä¼°", "å®¡æŸ¥", "å®¡æ ¸", "æ£€æŸ¥", "è¯Šæ–­", "æŠ¥å‘Š"],
                "response": "æˆ‘å¯ä»¥æä¾›å¤šç§é‡‡è´­åˆ†ææœåŠ¡ï¼š\n\n1. **éœ€æ±‚åˆ†æ** - è¯„ä¼°éœ€æ±‚å®Œæ•´æ€§å’Œåˆç†æ€§\n2. **ä»·æ ¼åˆ†æ** - å¯¹æ¯”å†å²ä»·æ ¼å’Œå¸‚åœºè¡Œæƒ…\n3. **ä¾›åº”å•†è¯„ä¼°** - åˆ†æä¾›åº”å•†èµ„è´¨å’Œèƒ½åŠ›\n4. **åˆåŒé£é™©åˆ†æ** - è¯†åˆ«æ½œåœ¨æ³•å¾‹å’Œå•†åŠ¡é£é™©\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦è¿›è¡Œå“ªç±»åˆ†æï¼Ÿ"
            },
            "supplier": {
                "keywords": ["ä¾›åº”å•†", "å‚å•†", "å‚å®¶", "ä¾›åº”å•†é€‰æ‹©", "ä¾›åº”å•†è¯„ä¼°", "èµ„è´¨"],
                "response": "å…³äºä¾›åº”å•†ç®¡ç†ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n1. **èµ„è´¨å®¡æ ¸** - æ£€æŸ¥ä¾›åº”å•†çš„è¥ä¸šæ‰§ç…§ã€èµ„è´¨è¯ä¹¦ç­‰\n2. **èƒ½åŠ›è¯„ä¼°** - è¯„ä¼°æŠ€æœ¯èƒ½åŠ›ã€äº¤ä»˜èƒ½åŠ›ã€æœåŠ¡æ°´å¹³\n3. **å†å²ä¸šç»©** - æŸ¥è¯¢è¿‡å¾€åˆä½œè®°å½•å’Œå®¢æˆ·è¯„ä»·\n4. **é£é™©é¢„è­¦** - è¯†åˆ«æ½œåœ¨çš„åˆä½œé£é™©\n\næ‚¨æƒ³äº†è§£å“ªä¸ªä¾›åº”å•†çš„ä¿¡æ¯ï¼Ÿ"
            },
            "process": {
                "keywords": ["æµç¨‹", "é‡‡è´­æµç¨‹", "æ­¥éª¤", "æ€ä¹ˆé‡‡è´­", "å¦‚ä½•é‡‡è´­", "ç¨‹åº"],
                "response": "æ ‡å‡†é‡‡è´­æµç¨‹ï¼š\n\n1. **éœ€æ±‚ç¡®è®¤** - æ˜ç¡®ç”¨é€”ã€åŠŸèƒ½ã€é¢„ç®—ã€äº¤ä»˜æ—¶é—´\n2. **æ–¹æ¡ˆåˆ¶å®š** - ç¡®å®šæŠ€æœ¯è§„æ ¼å’Œé‡‡è´­æ–¹å¼\n3. **ä¾›åº”å•†ç­›é€‰** - èµ„è´¨å®¡æ ¸å’Œåˆæ­¥è¯„ä¼°\n4. **è¯¢ä»·æ¯”ä»·** - è·å–æŠ¥ä»·å¹¶å¯¹æ¯”åˆ†æ\n5. **åˆåŒç­¾è®¢** - æ¡æ¬¾å®¡æ ¸å’Œæ­£å¼ç­¾ç½²\n6. **å±¥çº¦éªŒæ”¶** - äº¤ä»˜éªŒæ”¶å’Œä»˜æ¬¾\n\næ‚¨ç›®å‰åœ¨å“ªä¸ªç¯èŠ‚ï¼Ÿ"
            },
            "help": {
                "keywords": ["å¸®åŠ©", "åŠŸèƒ½", "èƒ½åšä»€ä¹ˆ", "æ€ä¹ˆç”¨", "ä½¿ç”¨", "å¸®åŠ©æˆ‘", "ä»‹ç»ä¸€ä¸‹"],
                "response": "æ™ºæ…§é‡‡è´­ç³»ç»Ÿå¯ä»¥ä¸ºæ‚¨æä¾›ä»¥ä¸‹æœåŠ¡ï¼š\n\nğŸ“‹ **éœ€æ±‚å®¡æŸ¥** - ä¸Šä¼ éœ€æ±‚æ–‡æ¡£ï¼Œè‡ªåŠ¨æ£€æŸ¥å®Œæ•´æ€§å’Œé£é™©ç‚¹\nğŸ’° **ä»·æ ¼å‚è€ƒ** - æŸ¥è¯¢å†å²ä»·æ ¼ï¼Œåˆ†æä»·æ ¼è¶‹åŠ¿\nğŸ“‘ **åˆåŒåˆ†æ** - è¯†åˆ«åˆåŒé£é™©æ¡æ¬¾ï¼Œæä¾›ä¿®æ”¹å»ºè®®\nğŸ’¬ **æ™ºèƒ½é—®ç­”** - å›ç­”é‡‡è´­ç›¸å…³é—®é¢˜ï¼Œæä¾›å»ºè®®\n\næ‚¨å¯ä»¥ç›´æ¥æè¿°éœ€æ±‚ï¼Œæˆ–ä¸Šä¼ ç›¸å…³æ–‡æ¡£è¿›è¡Œåˆ†æã€‚"
            },
            "thanks": {
                "keywords": ["è°¢è°¢", "æ„Ÿè°¢", "å¤šè°¢", "è¾›è‹¦äº†", "å¤ªå¥½äº†"],
                "response": "ä¸å®¢æ°”ï¼å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é‡‡è´­ç›¸å…³çš„é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚"
            }
        }

    def _create_session(self, session_id: str) -> str:
        """åˆ›å»ºæ–°ä¼šè¯"""
        self.sessions[session_id] = {
            "memory": ConversationBufferMemory(return_messages=True),
            "history": [],
            "created_at": None
        }
        return session_id

    def create_new_session(self) -> str:
        """åˆ›å»ºæ–°ä¼šè¯å¹¶è¿”å›session_id"""
        session_id = str(uuid.uuid4())
        self._create_session(session_id)
        return session_id

    def get_or_create_session(self, session_id: Optional[str] = None) -> str:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id and session_id in self.sessions:
            return session_id
        if session_id:
            self._create_session(session_id)
            return session_id
        return self.default_session_id

    def chat(self, user_input: str, session_id: Optional[str] = None) -> Dict[str, str]:
        """å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›å›å¤"""
        actual_session_id = self.get_or_create_session(session_id)
        session = self.sessions[actual_session_id]

        # å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯
        session["history"].append(HumanMessage(content=user_input))

        # å°è¯•ä½¿ç”¨LLMç”Ÿæˆå›å¤
        response = self._generate_llm_response(user_input, session["history"])

        # å¦‚æœLLMå¤±è´¥ï¼Œé™çº§åˆ°å…³é”®è¯åŒ¹é…
        if not response:
            response = self._generate_response(user_input, session["history"])

        # å­˜å‚¨AIå›å¤
        session["history"].append(AIMessage(content=response))

        return {
            "response": response,
            "session_id": actual_session_id
        }

    def _generate_llm_response(self, user_input: str, history: List[BaseMessage]) -> Optional[str]:
        """ä½¿ç”¨LLMç”Ÿæˆå›å¤"""
        if not self.llm_client:
            return None

        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": self.SYSTEM_PROMPT}
            ]

            # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆæœ€è¿‘10è½®å¯¹è¯ï¼‰
            recent_history = history[-20:] if len(history) > 20 else history
            for msg in recent_history:
                if isinstance(msg, HumanMessage):
                    messages.append({"role": "user", "content": msg.content})
                elif isinstance(msg, AIMessage):
                    messages.append({"role": "assistant", "content": msg.content})

            # è°ƒç”¨LLM API
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=messages,
                max_tokens=1024,
                temperature=0.7,
                top_p=0.9
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _generate_response(self, user_input: str, history: List[BaseMessage]) -> str:
        """ç”Ÿæˆå›å¤ï¼ˆå…³é”®è¯åŒ¹é…é™çº§æ–¹æ¡ˆï¼‰"""
        user_input_lower = user_input.lower()
        context = self._get_context_from_history(history)
        matched_response = self._match_intent(user_input_lower)

        if matched_response:
            return matched_response

        return self._get_default_response(user_input, context)

    def _match_intent(self, user_input: str) -> Optional[str]:
        """æ„å›¾åŒ¹é…"""
        priority_order = ["greetings", "help", "price", "requirements", "contract",
                         "server", "analysis", "supplier", "process", "thanks"]

        for category in priority_order:
            if category in self.keyword_responses:
                config = self.keyword_responses[category]
                for keyword in config["keywords"]:
                    if keyword.lower() in user_input:
                        return config["response"]

        return None

    def _get_context_from_history(self, history: List[BaseMessage]) -> str:
        """ä»å†å²æ¶ˆæ¯è·å–ä¸Šä¸‹æ–‡"""
        if len(history) <= 1:
            return ""

        recent_messages = history[-4:] if len(history) >= 4 else history[:-1]
        context_parts = []
        for msg in recent_messages:
            role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "åŠ©æ‰‹"
            context_parts.append(f"{role}: {msg.content[:50]}...")

        return "\n".join(context_parts)

    def _get_default_response(self, user_input: str, context: str) -> str:
        """è·å–é»˜è®¤å›å¤"""
        return f"""æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼

æˆ‘ç†è§£æ‚¨çš„é—®é¢˜æ˜¯å…³äºã€Œ{user_input[:30]}{'...' if len(user_input) > 30 else ''}ã€

ä½œä¸ºé‡‡è´­æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š

â€¢ ğŸ“‹ **éœ€æ±‚å®¡æŸ¥** - æ£€æŸ¥éœ€æ±‚æ–‡æ¡£çš„å®Œæ•´æ€§å’Œåˆç†æ€§
â€¢ ğŸ’° **ä»·æ ¼å‚è€ƒ** - æŸ¥è¯¢å†å²ä»·æ ¼å’Œè¿›è¡Œä»·æ ¼åˆ†æ
â€¢ ğŸ“‘ **åˆåŒåˆ†æ** - è¯†åˆ«åˆåŒä¸­çš„é£é™©æ¡æ¬¾
â€¢ ğŸ’¬ **é‡‡è´­å’¨è¯¢** - å›ç­”é‡‡è´­ç›¸å…³é—®é¢˜

è¯·å‘Šè¯‰æˆ‘æ‚¨å…·ä½“éœ€è¦å“ªæ–¹é¢çš„å¸®åŠ©ï¼Œæˆ–è€…ä¸Šä¼ ç›¸å…³æ–‡æ¡£è¿›è¡Œåˆ†æã€‚"""

    def clear_session(self, session_id: Optional[str] = None):
        """æ¸…ç©ºæŒ‡å®šä¼šè¯çš„å†å²"""
        target_session = session_id or self.default_session_id
        if target_session in self.sessions:
            self.sessions[target_session]["history"] = []
            self.sessions[target_session]["memory"].clear()

    def clear_all_sessions(self):
        """æ¸…ç©ºæ‰€æœ‰ä¼šè¯"""
        self.sessions.clear()
        self._create_session(self.default_session_id)

    def get_history(self, session_id: Optional[str] = None) -> List[Dict[str, str]]:
        """è·å–æŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²"""
        target_session = session_id or self.default_session_id
        if target_session not in self.sessions:
            return []

        history = []
        for msg in self.sessions[target_session]["history"]:
            history.append({
                "role": "user" if isinstance(msg, HumanMessage) else "assistant",
                "content": msg.content
            })
        return history

    def get_session_ids(self) -> List[str]:
        """è·å–æ‰€æœ‰ä¼šè¯ID"""
        return list(self.sessions.keys())
